{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "NLP.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw8L2bjTsTN9",
        "colab_type": "text"
      },
      "source": [
        "# NLP Basics: Implementing a pipeline to clean text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8IsbH8xsTOE",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing text data\n",
        "\n",
        "Cleaning up the text data is necessary to highlight attributes that you're going to want your machine learning system to pick up on. Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
        "1. **Remove punctuation**\n",
        "2. **Tokenization**\n",
        "3. **Remove stopwords**\n",
        "4. Lemmatize/Stem\n",
        "\n",
        "The first three steps are covered in this chapter as they're implemented in pretty much any text cleaning pipeline. Lemmatizing and stemming are covered in the next chapter as they're helpful but not critical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B63-BOSsTOJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "d198b5b7-4182-4619-c757-765ca86e688b"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t', header=None)\n",
        "data.columns = ['label', 'body_text']\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...  \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though  \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTxiOhNZsTOU",
        "colab_type": "code",
        "colab": {},
        "outputId": "8117b6e7-ad64-4643-b6e1-5107681310cd"
      },
      "source": [
        "# What does the cleaned version look like?\n",
        "data_cleaned = pd.read_csv(\"SMSSpamCollection_cleaned.tsv\", sep='\\t')\n",
        "data_cleaned.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>['ive', 'searching', 'right', 'words', 'thank', 'breather', 'promise', 'wont', 'take', 'help', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>['nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>['date', 'sunday']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                      body_text_nostop  \n",
              "0  ['ive', 'searching', 'right', 'words', 'thank', 'breather', 'promise', 'wont', 'take', 'help', '...  \n",
              "1  ['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005...  \n",
              "2                                 ['nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']  \n",
              "3                              ['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']  \n",
              "4                                                                                   ['date', 'sunday']  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbbZF4GhsTOa",
        "colab_type": "text"
      },
      "source": [
        "### Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCed_2posTOc",
        "colab_type": "code",
        "colab": {},
        "outputId": "1f6c1c40-0e7c-43da-a8df-1aa4fce33816"
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzKvIc_LsTOf",
        "colab_type": "code",
        "colab": {},
        "outputId": "84ff47e1-78c6-4e6e-902b-ad789102b362"
      },
      "source": [
        "\"I like NLP.\" == \"I like NLP\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzXoV4nsTOj",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc99c2de-6508-40bc-da0a-0b21c53eac6a"
      },
      "source": [
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text_nopunct\n",
        "\n",
        "data['body_text_clean'] = data['body_text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \n",
              "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...  \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...  \n",
              "2                                          Nah I dont think he goes to usf he lives around here though  \n",
              "3                          Even my brother is not like to speak with me They treat me like aids patent  \n",
              "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7iKx-RisTOo",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q0ft4lYsTOq",
        "colab_type": "code",
        "colab": {},
        "outputId": "e91d33b4-c5e8-4825-e74f-d8998ba47386"
      },
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    return tokens\n",
        "\n",
        "data['body_text_tokenized'] = data['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \\\n",
              "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
              "2                                          Nah I dont think he goes to usf he lives around here though   \n",
              "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
              "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
              "\n",
              "                                                                                   body_text_tokenized  \n",
              "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...  \n",
              "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...  \n",
              "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  \n",
              "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]  \n",
              "4                                                           [i, have, a, date, on, sunday, with, will]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz5muMubsTOt",
        "colab_type": "code",
        "colab": {},
        "outputId": "165a281e-8d16-40b2-8773-502a34adceff"
      },
      "source": [
        "'NLP' == 'nlp'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQrlYGD9sTOx",
        "colab_type": "text"
      },
      "source": [
        "### Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEDmCLvKsTOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXjLf56msTO5",
        "colab_type": "code",
        "colab": {},
        "outputId": "69040605-abe6-4d98-e8bd-05c0b99f8be9"
      },
      "source": [
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword]\n",
        "    return text\n",
        "\n",
        "data['body_text_nostop'] = data['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
              "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   ham   \n",
              "1  spam   \n",
              "2   ham   \n",
              "3   ham   \n",
              "4   ham   \n",
              "\n",
              "                                                                                             body_text  \\\n",
              "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
              "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
              "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
              "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
              "\n",
              "                                                                                       body_text_clean  \\\n",
              "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
              "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
              "2                                          Nah I dont think he goes to usf he lives around here though   \n",
              "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
              "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
              "\n",
              "                                                                                   body_text_tokenized  \\\n",
              "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...   \n",
              "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
              "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
              "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]   \n",
              "4                                                           [i, have, a, date, on, sunday, with, will]   \n",
              "\n",
              "                                                                                      body_text_nostop  \n",
              "0  [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...  \n",
              "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
              "2                                                 [nah, dont, think, goes, usf, lives, around, though]  \n",
              "3                                              [even, brother, like, speak, treat, like, aids, patent]  \n",
              "4                                                                                       [date, sunday]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqLsjKhJsTO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}